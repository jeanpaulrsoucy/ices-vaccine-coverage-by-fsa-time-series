---
title: "ICES Vaccine Coverage in Ontario by FSA Time Series"
author: "Jean-Paul R. Soucy"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, message=FALSE}
# load libraries
library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(readxl)
library(Covid19CanadaData) # devtools::install_github("ccodwg/Covid19CanadaData")
library(ggplot2)
library(ggpubr)
```

# Download data

We begin by downloading every unique version of [vaccine coverage dataset from ICES](https://www.ices.on.ca/DAS/AHRQ/COVID-19-Dashboard#vaccinecoverage).

```{r, echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
# download data from the Canadian COVID-19 Data Archive
dir.create("raw", showWarnings = FALSE) # create directory
Covid19CanadaData::dl_archive(
  "cd168371-86f5-41f3-9555-580cd50f9b3a", # dataset identifier
  date = "all",
  remove_duplicates = TRUE, # keep first appearance of each hash
  path = "raw",
  overwrite = FALSE)
files <- list.files("raw", full.names = TRUE)
```

```{r, echo=TRUE}
head(files)
```

There are a total of `r length(files)` unique files. A few of these will be dropped druing processing as they only have unique metadata, not unique data.

```{r, message=FALSE, results='hide'}
# load coverage data from a file
ds <- lapply(seq_along(files), function(x) {
  # print file
  cat(paste0(x, ": ", files[x]), fill = TRUE)
  # extract first column
  X1 <- read_xlsx(files[x], sheet = 3, range = "A1:A40", col_names = "X1") # don't skip leading blank rows
  # extract date of data
  d <- X1 %>%
    filter(grepl("^Dates of vaccination", X1)) %>%
    str_sub(-9) %>%
    as.Date(format = "%d%b%Y") %>%
    tibble(date = .)
  # extract start position of data (leading blank rows are automatically skipped)
  skip_rows <- grep("^FSA$", X1$X1) - 1
  # extract "% with at least 1 dose"
  dose_1 <- read_xlsx(files[x], sheet = 3, skip = skip_rows) %>%
    select(1, ifelse(x >=8 | x == 3, 6, 5)) %>%
    rename("fsa" = 1, "dose_1" = 2)
  # join data
  d <- bind_cols(d, dose_1)
  # extract "% with at least 2 doses"
  if (x >= 11) {
    # 2021-06-11 and later
    skip_rows <- read_xlsx(files[x], sheet = 4, range = "A1:A40", col_names = "X1") %>%
      {grep("^FSA$", .$X1)} - 1
    dose_2 <- read_xlsx(files[x], sheet = 4, skip = skip_rows) %>%
      select(1, 3) %>%
      rename("fsa" = 1, "dose_2" = 2)
    # join data
    d <- inner_join(d, dose_2, by = "fsa")
  }
  # extract "% with at least 3 doses"
  if (x >= 23) {
    # 2021-12-10 and later
    skip_rows <- read_xlsx(files[x], sheet = 5, range = "A1:A40", col_names = "X1") %>%
      {grep("^FSA$", .$X1)} - 1
    dose_3 <- read_xlsx(files[x], sheet = 5, skip = skip_rows) %>%
      select(1, 3) %>%
      rename("fsa" = 1, "dose_3" = 2)
    # join data
    d <- inner_join(d, dose_3, by = "fsa")
  }
  # return data
  d %>%
    # starting with 2021-10-08, some non-first dose cols don't get read as numeric
    mutate(across(!matches("^fsa$") & where(is.character), parse_number))
})

# merge dataset
ds <- ds %>%
  bind_rows() %>%
  # eliminate duplicates (e.g., 2021-12-10 and 2021-12-23 have identical but updated "terms of reference")
  distinct()

# list FSAs not represented in every unique dataset
fsa_exclude <- table(ds$fsa) %>% {.[. != max(.)]}

# remove a few random FSAs that are only represented a few times
ds <- ds %>%
  filter(!fsa %in% names(fsa_exclude))

# list valid FSAs
fsa_valid <- unique(ds$fsa)

# create long version of dataset for plotting
ds_long <- ds %>%
  pivot_longer(cols = c("dose_1", "dose_2", "dose_3"), names_to = "dose", values_to = "coverage")
```

# Dataset characteristics

Each dataset contains data up to a certain date. For example, the first dataset contains data up to `r min(ds$date)`. Second dose coverage is first added in the `r min(ds[!is.na(ds$dose_2), "date", drop = TRUE])` dataset. Third dose coverage is first added in the `r min(ds[!is.na(ds$dose_3), "date", drop = TRUE])` dataset. In total, there are `r length(unique(ds[!is.na(ds$dose_1), "date", drop = TRUE]))` time points for dose 1 coverage, `r length(unique(ds[!is.na(ds$dose_2), "date", drop = TRUE]))` time points for dose 2 coverage and `r length(unique(ds[!is.na(ds$dose_3), "date", drop = TRUE]))` time points for dose 3 coverage.

While there was a time the dataset was being updated only a more-or-less weekly basis, this was not consistent throughout the whole period, leading to temporal gaps in the dataset. Each point in the plot below refers to a unique update date for the dataset:

```{r, warning=FALSE}
ggplot(data = ds_long %>% filter(fsa == "K0A"),
       aes(x = date, y = coverage, group = dose, color = dose)) +
  geom_point() +
  geom_line() +
  theme_pubclean()
```

To further complicate matters, the dates of the datasets are not always on the same day of the week, reflecting changes to the update schedule:

```{r, echo=TRUE}
# which day of the week are the data dates?
setNames(weekdays(unique(ds$date)), unique(ds$date))
```

What about weird values in the dataset (coverage values over 100%)?

```{r, echo=TRUE}
# are there coverage values over 100%?
coverage_over_100 <- ds_long %>% filter(coverage > 1)
# K1P has some weird values in 2021-12-05
coverage_over_100
```

Okay, there are only `r nrow(coverage_over_100)`.

# Final dataset plot

Below is a plot of the final dataset (excluding the coverage values over 100% we identified above). Note the different y-axis scales for each plot.

```{r, warning=FALSE, message=FALSE}
# spaghetti plot
ggplot(mapping = aes(x = date, y = coverage)) +
  geom_line(data = ds_long %>%
              filter(dose %in% c("dose_1", "dose_2") & fsa != "K1P"),
            aes(group = fsa), alpha = 0.15) +
  geom_smooth(data = ds_long %>%
                filter(dose %in% c("dose_1", "dose_2") & fsa != "K1P"),
              method = "loess") +
  geom_point(data = ds_long %>%
               filter(dose == "dose_3"),
             alpha = 0.5, stroke = 0) +
  facet_wrap(~dose, scales = "free") +
  theme_pubclean()
```

```{r}
# save dataset
dir.create("data", showWarnings = FALSE) # create directory
write.csv(ds, "data/fsa_ts.csv", row.names = FALSE)
write.csv(ds_long, "data/fsa_ts_long.csv", row.names = FALSE)
```

# Appendix

Note that "received 2 doses" is officially defined in later datasets as:

* Individuals who have two-dose of COVID-19 vaccines authorized by Health Canada (e.g., those produced by Pfizer-BioNTech, Moderna, or Astrazeneca/Covishield), **OR**
* One dose of Johnson & Johnsonâ€™s Janssen COVID-19 vaccine, **OR** 
* One dose of a non-Health Canada authorized COVID-19 vaccine (e.g. CoronaVac/Sinovac and Sinopharm/BBIBP, or Sputnik V) **AND** one dose of a Health Canada authorized COVID-19 vaccine, **OR** 
* Three doses of any COVID-19 vaccine (whether or not the vaccines are authorized by Health Canada)

Since the Janssen vaccine received minimal use in Canada, we can be confident that the vast majority of people in the "received 2 doses" group did in fact receive two doses of Pfizer-BioNTech, Moderna and/or Astrazeneca/Covishield.
