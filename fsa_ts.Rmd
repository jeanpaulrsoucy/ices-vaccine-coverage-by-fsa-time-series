---
title: "ICES Vaccine Coverage in Ontario by FSA Time Series"
author: "Jean-Paul R. Soucy"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, message=FALSE}
# load libraries
library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(readxl)
library(Covid19CanadaData) # devtools::install_github("ccodwg/Covid19CanadaData")
library(ggplot2)
library(ggpubr)
```

# Download data

We begin by downloading every unique version of [vaccine coverage dataset from ICES](https://www.ices.on.ca/DAS/AHRQ/COVID-19-Dashboard#vaccinecoverage).

```{r, echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
# download data from the Canadian COVID-19 Data Archive
dir.create("raw", showWarnings = FALSE) # create directory
Covid19CanadaData::dl_archive(
  "cd168371-86f5-41f3-9555-580cd50f9b3a", # dataset identifier
  date = "all",
  remove_duplicates = TRUE, # keep first appearance of each hash
  path = "raw",
  overwrite = FALSE)
files <- list.files("raw", full.names = TRUE)
```

```{r, echo=TRUE}
head(files)
```

There are a total of `r length(files)` unique files. A few of these will be dropped during processing as they only have unique metadata, not unique data.

```{r, message=FALSE, results='hide'}
# load dictionaries to rename columns
dose_1_vars <- read.csv("colnames/dose_1.csv", stringsAsFactors = FALSE)
dose_1_vars$old_name <- gsub("\n", "\r\n", dose_1_vars$old_name)
dose_1_vars <- setNames(dose_1_vars$old_name, dose_1_vars$new_name)
dose_2_vars <- read.csv("colnames/dose_2.csv", stringsAsFactors = FALSE)
dose_2_vars$old_name <- gsub("\n", "\r\n", dose_2_vars$old_name)
dose_2_vars <- setNames(dose_2_vars$old_name, dose_2_vars$new_name)
dose_3_vars <- read.csv("colnames/dose_3.csv", stringsAsFactors = FALSE)
dose_3_vars$old_name <- gsub("\n", "\r\n", dose_3_vars$old_name)
dose_3_vars <- setNames(dose_3_vars$old_name, dose_3_vars$new_name)

# load coverage data from a file
ds <- lapply(seq_along(files), function(x) {
  # print file
  cat(paste0(x, ": ", files[x]), fill = TRUE)
  # extract first column
  X1 <- read_xlsx(files[x], sheet = 3, range = "A1:A40", col_names = "X1") # don't skip leading blank rows
  # extract date of data
  d <- X1 %>%
    filter(grepl("^Dates of vaccination", X1)) %>%
    str_sub(-9) %>%
    as.Date(format = "%d%b%Y") %>%
    tibble(date = .)
  # extract start position of data (leading blank rows are automatically skipped)
  skip_rows <- grep("^FSA$", X1$X1) - 1
  # extract "% with at least 1 dose"
  dose_1 <- read_xlsx(files[x], sheet = 3, skip = skip_rows) %>%
    rename(any_of(c("fsa" = "FSA", dose_1_vars))) %>%
    select(any_of(c("fsa", names(dose_1_vars))))
  # join data
  d <- bind_cols(d, dose_1)
  # extract "% with at least 2 doses"
  if (x >= 11) {
    # 2021-06-11 and later
    skip_rows <- read_xlsx(files[x], sheet = 4, range = "A1:A40", col_names = "X1") %>%
      {grep("^FSA$", .$X1)} - 1
    dose_2 <- read_xlsx(files[x], sheet = 4, skip = skip_rows) %>%
    rename(any_of(c("fsa" = "FSA", dose_2_vars))) %>%
    select(any_of(c("fsa", names(dose_2_vars))))
    # join data
    d <- inner_join(d, dose_2, by = "fsa")
  }
  # # extract "% with at least 3 doses"
  if (x >= 23) {
    # 2021-12-10 and later
    skip_rows <- read_xlsx(files[x], sheet = 5, range = "A1:A40", col_names = "X1") %>%
      {grep("^FSA$", .$X1)} - 1
    dose_3 <- read_xlsx(files[x], sheet = 5, skip = skip_rows) %>%
    rename(any_of(c("fsa" = "FSA", dose_3_vars))) %>%
    select(any_of(c("fsa", names(dose_3_vars))))
    # join data
    d <- inner_join(d, dose_3, by = "fsa")
  }
  # return data
  d %>%
    # convert all columns to numeric
    # this includes turning suppressed/missing values to NA
    mutate(across(!matches("^fsa$") & where(is.character), function(x) {
      parse_number(ifelse(x == "<100%", "0.9999", x), na = c(".", "Suppressed", "Suppressed due to data quality"))}))
})

# merge dataset
ds <- ds %>%
  bind_rows() %>%
  # eliminate duplicates (e.g., 2021-12-10 and 2021-12-23 have identical but updated "terms of reference")
  distinct()

# list FSAs not represented in every unique dataset
fsa_exclude <- table(ds$fsa) %>% {.[. != max(.)]}

# remove a few random FSAs that are only represented a few times
ds <- ds %>%
  filter(!fsa %in% names(fsa_exclude))

# list valid FSAs
# fsa_valid <- unique(ds$fsa)

# create long version of dataset for plotting
ds_long_dose_1 <- ds %>%
  select(matches("date|fsa|dose_1")) %>%
  rename("dose_1_all" = "dose_1") %>%
  pivot_longer(
    cols = matches("dose_1"),
    names_prefix = "dose_1_",
    names_to = "pop",
    values_to = "dose_1_coverage"
  )
ds_long_dose_2 <- ds %>%
  select(matches("date|fsa|dose_2")) %>%
  rename("dose_2_all" = "dose_2") %>%
  pivot_longer(
    cols = matches("dose_2"),
    names_prefix = "dose_2_",
    names_to = "pop",
    values_to = "dose_2_coverage"
  )
ds_long_dose_3 <- ds %>%
  select(matches("date|fsa|dose_3")) %>%
  rename("dose_3_all" = "dose_3") %>%
  pivot_longer(
    cols = matches("dose_3"),
    names_prefix = "dose_3_",
    names_to = "pop",
    values_to = "dose_3_coverage"
  )
ds_long <- full_join(
  ds_long_dose_1, ds_long_dose_2,
  by = c("date", "fsa", "pop")
)
ds_long <- full_join(
  ds_long, ds_long_dose_3,
  by = c("date", "fsa", "pop")
)
ds_long <- ds_long %>%
  pivot_longer(
    cols = matches("dose_"),
    names_pattern = "(dose_\\d)",
    names_to = "dose",
    values_to = "coverage"
)
```

# Dataset characteristics

Each dataset contains data up to a certain date. For example, the first dataset contains data up to `r min(ds$date)`. Second dose coverage is first added in the `r min(ds[!is.na(ds$dose_2), "date", drop = TRUE])` dataset. Third dose coverage is first added in the `r min(ds[!is.na(ds$dose_3), "date", drop = TRUE])` dataset. In total, there are `r length(unique(ds[!is.na(ds$dose_1), "date", drop = TRUE]))` time points for dose 1 coverage, `r length(unique(ds[!is.na(ds$dose_2), "date", drop = TRUE]))` time points for dose 2 coverage and `r length(unique(ds[!is.na(ds$dose_3), "date", drop = TRUE]))` time points for dose 3 coverage.

While there was a time the dataset was being updated only a more-or-less weekly basis, this was not consistent throughout the whole period, leading to temporal gaps in the dataset. Each point in the plot below refers to a unique update date for the dataset:

```{r, warning=FALSE}
ggplot(data = ds_long %>% filter(pop == "all" & fsa == "K0A"),
       aes(x = date, y = coverage, group = dose, color = dose)) +
  geom_point() +
  geom_line() +
  theme_pubclean()
```

To further complicate matters, the dates of the datasets are not always on the same day of the week, reflecting changes to the update schedule:

```{r, echo=TRUE}
# which day of the week are the data dates?
setNames(weekdays(unique(ds$date)), unique(ds$date))
```

What about weird values in the dataset (coverage values over 100%)?

```{r, echo=TRUE}
# are there coverage values over 100%?
coverage_over_100 <- ds_long %>% filter(coverage > 1)
# some FSAs have coverage values over 100% in some age categories, or even overall
# e.g., K1P has some weird overall coverage values in 2021-12-05
head(coverage_over_100)
```

Okay, there are `r nrow(coverage_over_100)`. A sample is given above.

```{r, echo=TRUE}
table(coverage_over_100$pop)
```

Most of these values are in specific population groups (particularly in the 18–24 category), rather than the overall coverage values. These reflect issues with the population denominators used by ICES.

# Final dataset plot

Below is a plot of the final dataset for overall coverage (excluding the coverage values over 100% we identified above). Note the different y-axis scales for each plot.

```{r, warning=FALSE, message=FALSE}
# spaghetti plot
ggplot(mapping = aes(x = date, y = coverage)) +
  geom_line(data = ds_long %>%
              filter(pop == "all" & coverage < 1),
            aes(group = fsa), alpha = 0.15) +
  geom_smooth(data = ds_long %>%
                filter(pop == "all" & coverage < 1),
              method = "loess") +
  facet_wrap(~dose, scales = "free") +
  theme_pubclean()
```

Below is a plot for a specific age group, 70–74 (again, excluding coverage values over 100%). Note that the age groups reported over time have been somewhat inconsistent, hence why some population groups are reported over the entire time series and some over only a short period. For example, 3rd dose coverage was originally reported only for older age groups.

```{r, warning=FALSE, message=FALSE}
# spaghetti plot
ggplot(mapping = aes(x = date, y = coverage)) +
  geom_line(data = ds_long %>%
              filter(pop == "70_74" & coverage < 1),
            aes(group = fsa), alpha = 0.15) +
  geom_smooth(data = ds_long %>%
                filter(pop == "70_74" & coverage < 1),
              method = "loess") +
  facet_wrap(~dose, scales = "free") +
  theme_pubclean()
```

```{r}
# save dataset
dir.create("data", showWarnings = FALSE) # create directory
write.csv(ds, "data/fsa_ts.csv", row.names = FALSE)
write.csv(ds_long, "data/fsa_ts_long.csv", row.names = FALSE)
```

# Bonus dataset: Cumulative case, hospitalization & death rates by FSA

A bonus dataset: the cumulative case, hospitalization and mortality rates by FSA. Additionally, whether the FSA was among the [114 identified for vaccine prioritization by the province in early April 2021](https://toronto.ctvnews.ca/full-list-of-ontario-neighbourhoods-where-the-covid-19-vaccine-will-be-available-to-those-18-1.5379755).

A few notes about these data: from 2021-03-29 to 2021-05-10, hospitalizations and mortality were combined into a single metric; starting on 2021-05-17, these two metrics were disaggregated. Small cell sizes may be censored, which is represented as an NA in the dataset.

```{r, message=FALSE, results='hide'}
# copy file list
files_chd <- files

# drop x = 19 (2021-09-20), the next file x = 20 (2021-09-28) is just a corrected version of this first file
files_chd <- files_chd[-19]

# load coverage data from a file
ds_chd <- lapply(seq_along(files_chd), function(x) {
  # print file
  cat(paste0(x, ": ", files_chd[x]), fill = TRUE)
  # extract first column
  X1 <- read_xlsx(files_chd[x], sheet = 3, range = "A1:A40", col_names = "X1") # don't skip leading blank rows
  # extract date of data
  d <- X1 %>%
    filter(grepl("^Dates of vaccination", X1)) %>%
    str_sub(-9) %>%
    as.Date(format = "%d%b%Y") %>%
    tibble(date = .)
  # extract start position of data (leading blank rows are automatically skipped)
  skip_rows <- grep("^FSA$", X1$X1) - 1
  # extract data
  chd <- read_xlsx(files_chd[x], sheet = 3, skip = skip_rows) %>%
    # fix case numbers for first spreadsheet
    {if (x == 1) {
      mutate(., `COVID-19 cases\r\n(per 100)` = `COVID-19 cases\r\n(per 100)` * 100)
      } else {
        .
        }} %>%
    rename(any_of(c(
      "fsa" = "FSA",
      "cum_cases_per_100" = "COVID-19 cases\r\n(per 100)",
      "cum_hospitalizations_deaths_per_1000" = "COVID-10 hospitalizations/deaths\r\n(per 1,000)",
      "cum_hospitalizations_per_1000" = "COVID-19 hospitalizations\r\n(per 1,000)",
      "cum_deaths_per_1000" = "COVID-19 deaths\r\n(per 1,000)"
      ))) %>%
    select(any_of(c(
      "date",
      "fsa",
      "cum_cases_per_100",
      "cum_hospitalizations_deaths_per_1000",
      "cum_hospitalizations_per_1000",
      "cum_deaths_per_1000"
    )))
  # join data
  d <- bind_cols(d, chd)
  # return data
  d %>%
    # convert all columns to numeric
    # this includes turning suppressed/missing values to NA
    mutate(across(!matches("^fsa$") & where(is.character), function(x) {
      parse_number(x, na = c(".", "*", "Suppressed", "Suppressed due to data quality"))}))
})

# merge dataset
ds_chd <- ds_chd %>%
  bind_rows() %>%
  # eliminate duplicates (e.g., 2021-12-10 and 2021-12-23 have identical but updated "terms of reference")
  distinct()

# list FSAs not represented in every unique dataset
fsa_exclude <- table(ds_chd$fsa) %>% {.[. != max(.)]}

# remove a few random FSAs that are only represented a few times
ds_chd <- ds_chd %>%
  filter(!fsa %in% names(fsa_exclude))

# add hot spot identifier from dataset with date 2021-04-12
ds_chd <- ds_chd %>%
  left_join(
    read_xlsx(files_chd[3], sheet = 3, skip = 24) %>%
      transmute(fsa = FSA, hot_spot_fsa = ifelse(`Hot Spot Community` == "Yes", 1, 0)) %>%
      replace_na(list(hot_spot_fsa = 0)),
    by = "fsa"
  ) %>%
  select(
    date,
    fsa,
    hot_spot_fsa,
    cum_cases_per_100,
    cum_hospitalizations_deaths_per_1000,
    cum_hospitalizations_per_1000,
    cum_deaths_per_1000
  )

# convert dataset to long
ds_chd_long <- ds_chd %>%
  pivot_longer(
    cols = -c(date, fsa, hot_spot_fsa),
    names_to = "metric",
    values_to = "value"
  )
```

These metrics are plotted below. First, for an example FSA:

```{r, warning=FALSE, message=FALSE}
ggplot(data = ds_chd_long %>% filter(fsa == "K0A"), mapping = aes(x = date, y = value)) +
  geom_line(aes(group = fsa), alpha = 0.15) +
  geom_smooth(method = "loess") +
  facet_wrap(~metric, scales = "free") +
  theme_pubclean()
```

Then, the whole dataset:

```{r, warning=FALSE, message=FALSE}
ggplot(data = ds_chd_long, mapping = aes(x = date, y = value)) +
  geom_line(aes(group = fsa), alpha = 0.15) +
  geom_smooth(method = "loess") +
  facet_wrap(~metric, scales = "free") +
  theme_pubclean()
```

```{r}
# save dataset
write.csv(ds_chd, "data/fsa_metrics_ts.csv", row.names = FALSE)
write.csv(ds_chd_long, "data/fsa_metrics_ts_long.csv", row.names = FALSE)
```

# Appendix

## Data processing notes

* Coverage values censored due to small cell sizes or data quality issues (".", "Suppressed", "Suppressed due to data quality") have been replaced with `NA`.
* Coverage values given as "<100%" have been replaced with 0.9999 (i.e., 99.99%): this occurs when the count for unvaccinated individuals (total - vaccinated) was between 1 and 5
* The data documentation notes that vaccine coverage estimates >100% are due to the addition of unlinked records of vaccinated individuals

## Definition of "received 2 doses"

Note that "received 2 doses" is officially defined in later datasets as:

* Individuals who have two-dose of COVID-19 vaccines authorized by Health Canada (e.g., those produced by Pfizer-BioNTech, Moderna, or Astrazeneca/Covishield), **OR**
* One dose of Johnson & Johnson’s Janssen COVID-19 vaccine, **OR** 
* One dose of a non-Health Canada authorized COVID-19 vaccine (e.g. CoronaVac/Sinovac and Sinopharm/BBIBP, or Sputnik V) **AND** one dose of a Health Canada authorized COVID-19 vaccine, **OR** 
* Three doses of any COVID-19 vaccine (whether or not the vaccines are authorized by Health Canada)

Since the Janssen vaccine received minimal use in Canada, we can be confident that the vast majority of people in the "received 2 doses" group did in fact receive two doses of Pfizer-BioNTech, Moderna and/or Astrazeneca/Covishield.
